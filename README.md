# PALANOG_WebApp

######## INSTALLATION FOR MY WEB APPLICATION ##############
  
  
  STEP 1: YOU MUST IMPORT THE laurence.sql in localhost.
 
  STEP 2: AFTER YOU UPLOADED THE FILE. THE DATABASE NAME IS "laurence" DATABASE TABLE IS "tbl_lau".
  
  STEP 3: NOW VISIT THIS LINK: http://localhost/Laurence/Lau_cont/main
  
  
 
 
 
 
 # PALANOG_HadoopHDFS
 
 INSTALLING HADOOP AND HOW HDFS ARCHITECTURE (NameNode and DataNode) WORKS
 
 First I Installed Java
  
  ![](images/im1.png)
  
  
  And then I Installed Hadoop (Configuring codes in some of Hadoop XML files: core,mapred,yarn,hdfs,Hadoop env. Codes source from Web) and I created Name Node and Data Node in data Folder and in HDFS XML
  
  ![](images/im2.png)
  
  
  
  
                                            CMD CONFIGURE
                                            
                                            
  Checking the Java if it’s already installed (Checking the Java Version)
  ![](images/im3.png)
  
  
  Configuring and Creating Namenode (by typing “hdfs name node -format”)
  ![](images/im4.png)
  
  
  
  After creating Name Node starting all cmd in Hadoop sbin by typing “start-all.cmd”
  ![](images/im5.png)
  
  
  To show and start the Data Node
  ![](images/im6.png)
  
  
  Resource Manager
  ![](images/im7.png)
  
  
  And Node Manager
  ![](images/im8.png)
  
  
  
  
  Checking the localhost if the Hadoop has already installed by typing “http://localhost:9870/” but first don’t close all the CMD running (NameNode, DataNode, ResourceManager,NodeManager) so that the localhost link is working.
  
  ![](images/im9.png)
  
  
  
  
  After accessing the localhost link in the web browser you will see this:
  ![](images/im10.png)
  
  
  SUCCESSFULLY HADOOP HAS BEEN INSTALLED and Name Node and Data Node HAS BEEN CREATED!!!
  ![](images/im11.png)


(I learned about how to start up installing hadoop with Java in my PC and explore how it works especially the HDFS, and if I want really to know and understand the concept of Hadoop flows, learning how Hadoop does it will give me either a fairly deep understanding and learning. And maybe I can also find that if I run exploration, putting data in the Hadoop Distributed File System and giving my output access to HDFS architecture, it maybe become handy and easy to learn.)
 
  
